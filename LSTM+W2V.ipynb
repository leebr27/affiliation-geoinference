{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras import preprocessing as kprocessing\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Suppress \"SettingWithCopyWarning\"\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "# https://medium.com/@claude.feldges/text-classification-with-tf-idf-lstm-bert-a-quantitative-comparison-b8409b556cb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_spacy_mapaffil = pd.read_parquet(\"data/clean_spacy_mapaffil.parquet\", engine=\"fastparquet\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_affiliations = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_spacy_mapaffil.head(num_affiliations)\n",
    "city_counts = df['city'].value_counts()\n",
    "single_instance_cities = city_counts[city_counts == 1].index.tolist()\n",
    "num_affiliations -= len(single_instance_cities)\n",
    "filtered_df = df[~df['city'].isin(single_instance_cities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['city'] = filtered_df['city'].astype('category')\n",
    "filtered_df['label'] = filtered_df['city'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_df['affiliation']\n",
    "y_class = filtered_df['city']\n",
    "\n",
    "lab = LabelBinarizer()\n",
    "lab.fit(y_class)\n",
    "y = lab.transform(y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_test_size = (filtered_df['city'].nunique()) / num_affiliations\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=calculated_test_size if calculated_test_size > 0.1 else 0.1, stratify=filtered_df['label'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 5600\n",
    "tokenizer = kprocessing.text.Tokenizer(lower=True, split=' ', num_words=max_words, oov_token=\"<pad>\", filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "voc = tokenizer.word_index\n",
    "reverse_voc = dict([(value, key) for (key, value) in voc.items()])\n",
    "\n",
    "max_len = 40\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_seq = kprocessing.sequence.pad_sequences(sequences, maxlen=max_len)\n",
    "X_test_seq = kprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"word2vec-google-news-300.model\"):\n",
    "    w2v = gensim.models.KeyedVectors.load(\"word2vec-google-news-300.model\")\n",
    "else:\n",
    "    w2v = api.load(\"word2vec-google-news-300\") \n",
    "    w2v.save(\"word2vec-google-news-300.model\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix=np.zeros((max_words+1, 300))\n",
    "for i in range(max_words):\n",
    "    w = reverse_voc[i+1]\n",
    "    if w in w2v:\n",
    "        emb_matrix[i+1,:] = w2v[w]\n",
    "emb_size = emb_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape = X_train_seq[0,:].shape,name='input')\n",
    "x = layers.Embedding(max_words+1,emb_size,weights=[emb_matrix],trainable=False, name='embedding')(input_)\n",
    "x = layers.LSTM(15, dropout=0.2, name='lstm')(x)\n",
    "x = layers.Dropout(0.2, name='dropout')(x)\n",
    "x = layers.Dense(64, activation='relu', name='dense')(x)\n",
    "output = layers.Dense(len(filtered_df[\"city\"].unique()),activation='softmax', name='classification')(x)\n",
    "\n",
    "model = models.Model(input_, output)\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.01, beta_1=0.9)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_seq, y_train, batch_size=64, shuffle=True, epochs=10, validation_data=(X_test_seq, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: {:.1%}'.format(history.history['val_accuracy'][-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
